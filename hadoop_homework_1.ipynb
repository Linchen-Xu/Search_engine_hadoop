{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import urllib.request\n",
    "import urllib.parse\n",
    "import re\n",
    "import urllib.request, urllib.parse, http.cookiejar\n",
    "import codecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#获取网页内容\n",
    "\n",
    "#读取网页\n",
    "def getHtml(url):\n",
    "    cj = http.cookiejar.CookieJar()\n",
    "    opener = urllib.request.build_opener(urllib.request.HTTPCookieProcessor(cj))\n",
    "    opener.addheaders = [('User-Agent',\n",
    "    'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2272.101 Safari/537.36'),('Cookie', '4564564564564564565646540')]\n",
    "\n",
    "    urllib.request.install_opener(opener)\n",
    "    try:\n",
    "        html_bytes = urllib.request.urlopen(url).read()\n",
    "    except:\n",
    "        return '',False\n",
    "    \n",
    "    html_string = ''\n",
    "    try:\n",
    "        html_string = html_bytes.decode('utf-8')\n",
    "    except:\n",
    "        try:\n",
    "            html_string = html_bytes.decode('gbk')\n",
    "        except:\n",
    "            try:\n",
    "                html_string = html_bytes.decode('gb2312')\n",
    "            except:\n",
    "                return '',False\n",
    "    return html_string,True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#分词\n",
    "import sys\n",
    "import jieba\n",
    "from os import path\n",
    "\n",
    "re_cdata=re.compile('//<!\\[CDATA\\[[^>]*//\\]\\]>',re.I)#处理CDATA\n",
    "re_doctype=re.compile('<!DOCTYPE HTML PUBLIC[^>]*>',re.I)  \n",
    "re_doctype2=re.compile('<!DOCTYPE HTML[^>]*>',re.I) \n",
    "re_script=re.compile(r'<script[\\s\\S]+?/script>',re.I)#处理script\n",
    "re_style=re.compile(r'<style[\\s\\S]+?/style>',re.I)#处理style\n",
    "re_div=re.compile('<\\s*div[^>]*>[^<]*<\\s*/\\s*div\\s*>',re.I)#处理div\n",
    "re_br = re.compile('<br\\s*?/?>',re.I)  \n",
    "re_h=re.compile('</?\\w+[^>]*>',re.I)#HTML标签\n",
    "# re_comment=re.compile('<!--[^>]*-->')#HTML注释\n",
    "re_comment = re.compile('<!--[\\s\\S]*-->',re.I)  \n",
    "\n",
    "def processHtml(link, file_content):\n",
    "    file_content = re_cdata.sub('',file_content)\n",
    "    file_content = re_doctype.sub('',file_content)\n",
    "    file_content = re_doctype2.sub('',file_content)\n",
    "    file_content = re_script.sub('',file_content)\n",
    "    file_content = re_style.sub('',file_content)\n",
    "    file_content = re_div.sub('',file_content)\n",
    "#     file_content = re_br.sub('\\n',file_content)\n",
    "    file_content = re_h.sub('',file_content)\n",
    "    file_content = re_comment.sub('',file_content)\n",
    "    file_content = re.sub('[\\r\\n\\t  !©<>“”»《》!:,?。.：？，！、　•\"_◆×|()-【】]', '', file_content)\n",
    "    file_content = re.sub('DOCTYPEdoctypehtml', '', file_content)\n",
    "#     file_content = re.sub('', '', file_content)\n",
    "#     print('file_content:',file_content)\n",
    "    seg_list = jieba.cut_for_search(file_content)\n",
    "    return link +  ' ' +  '/'.join(seg_list) + '\\n'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#爬取层数变换\n",
    "crawl_turns = 1\n",
    "#网址列表\n",
    "rel = 'https://www.baidu.com/'\n",
    "arr = [[rel]] * 3\n",
    "success_crwal = True\n",
    "#爬取网页数量\n",
    "crawl_total = 500\n",
    "#保存链接数量\n",
    "save_total = crawl_total - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\xlc\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.815 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "j = 1\n",
    "arr[j] = []\n",
    "#遍历列表，爬取所有网页\n",
    "element = rel\n",
    "#获取网页内容\n",
    "html_doc,success_crwal = getHtml(element)\n",
    "if success_crwal:\n",
    "    #需爬取网页总数-1\n",
    "    crawl_total -= 1\n",
    "    soup = BeautifulSoup(html_doc, 'html.parser')\n",
    "    #处理后写入文件\n",
    "    f = codecs.open('./saved_html/' + str(crawl_total) + '.txt',\"w\",encoding=\"utf-8\")\n",
    "    f.write(processHtml(element, str(soup)))\n",
    "    f.close()\n",
    "    link_arr = [s.extract() for s in soup('a')]\n",
    "    for element_addr in link_arr:\n",
    "        try:\n",
    "            addr = element_addr['href'][0]\n",
    "            #链接指向网页\n",
    "            if ((addr == 'h' or addr == '/') and (not element_addr['href'].split()[0].endswith('.apk'))):\n",
    "                if addr == '/':\n",
    "                    #相对链接\n",
    "                    addr = element.split('//')[0] + '//' + element.split('//')[1].split('/')[0] + element_addr['href'].split()[0]\n",
    "                    #链接不在已访问列表中\n",
    "                    if addr not in arr[2]:\n",
    "                        #是符合要求的网页，需要保存的总网页数-1\n",
    "                        save_total -= 1\n",
    "                        arr[j].append(addr)\n",
    "                        arr[2].append(addr)\n",
    "                        pass\n",
    "                    pass\n",
    "                else:\n",
    "                    #绝对链接\n",
    "                    addr = element_addr['href'].split()[0]\n",
    "                    #链接不在已访问列表中\n",
    "                    if addr not in arr[2]:\n",
    "                        #是符合要求的网页，需要保存的总网页数-1\n",
    "                        save_total -= 1\n",
    "                        arr[j].append(addr)\n",
    "                        arr[2].append(addr)\n",
    "                        pass\n",
    "                    pass\n",
    "        except:\n",
    "            pass\n",
    "        pass\n",
    "    pass\n",
    "pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "crawl_total: 498\n",
      "crawl_total: 497\n",
      "crawl_total: 496\n",
      "crawl_total: 495\n",
      "crawl_total: 494\n",
      "crawl_total: 493\n",
      "crawl_total: 492\n",
      "crawl_total: 491\n",
      "crawl_total: 490\n",
      "crawl_total: 489\n",
      "crawl_total: 488\n",
      "crawl_total: 487\n",
      "crawl_total: 486\n",
      "crawl_total: 485\n",
      "crawl_total: 484\n",
      "crawl_total: 483\n",
      "crawl_total: 482\n",
      "crawl_total: 481\n",
      "crawl_total: 480\n",
      "crawl_total: 479\n",
      "crawl_total: 478\n",
      "crawl_total: 477\n",
      "crawl_total: 476\n",
      "crawl_total: 475\n",
      "crawl_total: 474\n",
      "crawl_total: 473\n",
      "crawl_total: 472\n",
      "crawl_total: 471\n",
      "crawl_total: 470\n",
      "crawl_total: 469\n",
      "crawl_total: 468\n",
      "crawl_total: 467\n",
      "crawl_total: 466\n",
      "crawl_total: 465\n",
      "crawl_total: 464\n",
      "crawl_total: 463\n",
      "crawl_total: 462\n",
      "crawl_total: 461\n",
      "crawl_total: 460\n",
      "crawl_total: 459\n",
      "crawl_total: 458\n",
      "crawl_total: 457\n",
      "crawl_total: 456\n",
      "crawl_total: 455\n",
      "crawl_total: 454\n",
      "crawl_total: 453\n",
      "crawl_total: 452\n",
      "crawl_total: 451\n",
      "crawl_total: 450\n",
      "crawl_total: 449\n",
      "crawl_total: 448\n",
      "crawl_total: 447\n",
      "crawl_total: 446\n",
      "crawl_total: 445\n",
      "crawl_total: 444\n",
      "crawl_total: 443\n",
      "crawl_total: 442\n",
      "crawl_total: 441\n",
      "crawl_total: 440\n",
      "crawl_total: 439\n",
      "crawl_total: 438\n",
      "crawl_total: 437\n",
      "crawl_total: 436\n",
      "crawl_total: 435\n",
      "crawl_total: 434\n",
      "crawl_total: 433\n",
      "crawl_total: 432\n",
      "crawl_total: 431\n",
      "crawl_total: 430\n",
      "crawl_total: 429\n",
      "crawl_total: 428\n",
      "crawl_total: 427\n",
      "crawl_total: 426\n",
      "crawl_total: 425\n",
      "crawl_total: 424\n",
      "crawl_total: 423\n",
      "crawl_total: 422\n",
      "crawl_total: 421\n",
      "crawl_total: 420\n",
      "crawl_total: 419\n",
      "crawl_total: 418\n",
      "crawl_total: 417\n",
      "crawl_total: 416\n",
      "crawl_total: 415\n",
      "crawl_total: 414\n",
      "crawl_total: 413\n",
      "crawl_total: 412\n",
      "crawl_total: 411\n",
      "crawl_total: 410\n",
      "crawl_total: 409\n",
      "crawl_total: 408\n",
      "crawl_total: 407\n",
      "crawl_total: 406\n",
      "crawl_total: 405\n",
      "crawl_total: 404\n",
      "crawl_total: 403\n",
      "crawl_total: 402\n",
      "crawl_total: 401\n",
      "crawl_total: 400\n",
      "crawl_total: 399\n",
      "crawl_total: 398\n",
      "crawl_total: 397\n",
      "crawl_total: 396\n",
      "crawl_total: 395\n",
      "crawl_total: 394\n",
      "crawl_total: 393\n",
      "crawl_total: 392\n",
      "crawl_total: 391\n",
      "crawl_total: 390\n",
      "crawl_total: 389\n",
      "crawl_total: 388\n",
      "crawl_total: 387\n",
      "crawl_total: 386\n",
      "crawl_total: 385\n",
      "crawl_total: 384\n",
      "crawl_total: 383\n",
      "crawl_total: 382\n",
      "crawl_total: 381\n",
      "crawl_total: 380\n",
      "crawl_total: 379\n",
      "crawl_total: 378\n",
      "crawl_total: 377\n",
      "crawl_total: 376\n",
      "crawl_total: 375\n",
      "crawl_total: 374\n",
      "crawl_total: 373\n",
      "crawl_total: 372\n",
      "crawl_total: 371\n",
      "crawl_total: 370\n",
      "crawl_total: 369\n",
      "crawl_total: 368\n",
      "crawl_total: 367\n",
      "crawl_total: 366\n",
      "crawl_total: 365\n",
      "crawl_total: 364\n",
      "crawl_total: 363\n",
      "crawl_total: 362\n",
      "crawl_total: 361\n",
      "crawl_total: 360\n",
      "crawl_total: 359\n",
      "crawl_total: 358\n",
      "crawl_total: 357\n",
      "crawl_total: 356\n",
      "crawl_total: 355\n",
      "crawl_total: 354\n",
      "crawl_total: 353\n",
      "crawl_total: 352\n",
      "crawl_total: 351\n",
      "crawl_total: 350\n",
      "crawl_total: 349\n",
      "crawl_total: 348\n",
      "crawl_total: 347\n",
      "crawl_total: 346\n",
      "crawl_total: 345\n",
      "crawl_total: 344\n",
      "crawl_total: 343\n",
      "crawl_total: 342\n",
      "crawl_total: 341\n",
      "crawl_total: 340\n",
      "crawl_total: 339\n",
      "crawl_total: 338\n",
      "crawl_total: 337\n",
      "crawl_total: 336\n",
      "crawl_total: 335\n",
      "crawl_total: 334\n",
      "crawl_total: 333\n",
      "crawl_total: 332\n",
      "crawl_total: 331\n",
      "crawl_total: 330\n",
      "crawl_total: 329\n",
      "crawl_total: 328\n",
      "crawl_total: 327\n",
      "crawl_total: 326\n",
      "crawl_total: 325\n",
      "crawl_total: 324\n",
      "crawl_total: 323\n",
      "crawl_total: 322\n",
      "crawl_total: 321\n",
      "crawl_total: 320\n",
      "crawl_total: 319\n",
      "crawl_total: 318\n",
      "crawl_total: 317\n",
      "crawl_total: 316\n",
      "crawl_total: 315\n",
      "crawl_total: 314\n",
      "crawl_total: 313\n",
      "crawl_total: 312\n",
      "crawl_total: 311\n",
      "crawl_total: 310\n",
      "crawl_total: 309\n",
      "crawl_total: 308\n",
      "crawl_total: 307\n",
      "crawl_total: 306\n",
      "crawl_total: 305\n",
      "crawl_total: 304\n",
      "crawl_total: 303\n",
      "crawl_total: 302\n",
      "crawl_total: 301\n",
      "crawl_total: 300\n",
      "crawl_total: 299\n",
      "crawl_total: 298\n",
      "crawl_total: 297\n",
      "crawl_total: 296\n",
      "crawl_total: 295\n",
      "crawl_total: 294\n",
      "crawl_total: 293\n",
      "crawl_total: 292\n",
      "crawl_total: 291\n",
      "crawl_total: 290\n",
      "crawl_total: 289\n",
      "crawl_total: 288\n",
      "crawl_total: 287\n",
      "crawl_total: 286\n",
      "crawl_total: 285\n",
      "crawl_total: 284\n",
      "crawl_total: 283\n",
      "crawl_total: 282\n",
      "crawl_total: 281\n",
      "crawl_total: 280\n",
      "crawl_total: 279\n",
      "crawl_total: 278\n",
      "crawl_total: 277\n",
      "crawl_total: 276\n",
      "crawl_total: 275\n",
      "crawl_total: 274\n",
      "crawl_total: 273\n",
      "crawl_total: 272\n",
      "crawl_total: 271\n",
      "crawl_total: 270\n",
      "crawl_total: 269\n",
      "crawl_total: 268\n",
      "crawl_total: 267\n",
      "crawl_total: 266\n",
      "crawl_total: 265\n",
      "crawl_total: 264\n",
      "crawl_total: 263\n",
      "crawl_total: 262\n",
      "crawl_total: 261\n",
      "crawl_total: 260\n",
      "crawl_total: 259\n",
      "crawl_total: 258\n",
      "crawl_total: 257\n",
      "crawl_total: 256\n",
      "crawl_total: 255\n",
      "crawl_total: 254\n",
      "crawl_total: 253\n",
      "crawl_total: 252\n",
      "crawl_total: 251\n",
      "crawl_total: 250\n",
      "crawl_total: 249\n",
      "crawl_total: 248\n",
      "crawl_total: 247\n",
      "crawl_total: 246\n",
      "crawl_total: 245\n",
      "crawl_total: 244\n",
      "crawl_total: 243\n",
      "crawl_total: 242\n",
      "crawl_total: 241\n",
      "crawl_total: 240\n",
      "crawl_total: 239\n",
      "crawl_total: 238\n",
      "crawl_total: 237\n",
      "crawl_total: 236\n",
      "crawl_total: 235\n",
      "crawl_total: 234\n",
      "crawl_total: 233\n",
      "crawl_total: 232\n",
      "crawl_total: 231\n",
      "crawl_total: 230\n",
      "crawl_total: 229\n",
      "crawl_total: 228\n",
      "crawl_total: 227\n",
      "crawl_total: 226\n",
      "crawl_total: 225\n",
      "crawl_total: 224\n",
      "crawl_total: 223\n",
      "crawl_total: 222\n",
      "crawl_total: 221\n",
      "crawl_total: 220\n",
      "crawl_total: 219\n",
      "crawl_total: 218\n",
      "crawl_total: 217\n",
      "crawl_total: 216\n",
      "crawl_total: 215\n",
      "crawl_total: 214\n",
      "crawl_total: 213\n",
      "crawl_total: 212\n",
      "crawl_total: 211\n",
      "crawl_total: 210\n",
      "crawl_total: 209\n",
      "crawl_total: 208\n",
      "crawl_total: 207\n",
      "crawl_total: 206\n",
      "crawl_total: 205\n",
      "crawl_total: 204\n",
      "crawl_total: 203\n",
      "crawl_total: 202\n",
      "crawl_total: 201\n",
      "crawl_total: 200\n",
      "crawl_total: 199\n",
      "crawl_total: 198\n",
      "crawl_total: 197\n",
      "crawl_total: 196\n",
      "crawl_total: 195\n",
      "crawl_total: 194\n",
      "crawl_total: 193\n",
      "crawl_total: 192\n",
      "crawl_total: 191\n",
      "crawl_total: 190\n",
      "crawl_total: 189\n",
      "crawl_total: 188\n",
      "crawl_total: 187\n",
      "crawl_total: 186\n",
      "crawl_total: 185\n",
      "crawl_total: 184\n",
      "crawl_total: 183\n",
      "crawl_total: 182\n",
      "crawl_total: 181\n",
      "crawl_total: 180\n",
      "crawl_total: 179\n",
      "crawl_total: 178\n",
      "crawl_total: 177\n",
      "crawl_total: 176\n",
      "crawl_total: 175\n",
      "crawl_total: 174\n",
      "crawl_total: 173\n",
      "crawl_total: 172\n",
      "crawl_total: 171\n",
      "crawl_total: 170\n",
      "crawl_total: 169\n",
      "crawl_total: 168\n",
      "crawl_total: 167\n",
      "crawl_total: 166\n",
      "crawl_total: 165\n",
      "crawl_total: 164\n",
      "crawl_total: 163\n",
      "crawl_total: 162\n",
      "crawl_total: 161\n",
      "crawl_total: 160\n",
      "crawl_total: 159\n",
      "crawl_total: 158\n",
      "crawl_total: 157\n",
      "crawl_total: 156\n",
      "crawl_total: 155\n",
      "crawl_total: 154\n",
      "crawl_total: 153\n",
      "crawl_total: 152\n",
      "crawl_total: 151\n",
      "crawl_total: 150\n",
      "crawl_total: 149\n",
      "crawl_total: 148\n",
      "crawl_total: 147\n",
      "crawl_total: 146\n",
      "crawl_total: 145\n",
      "crawl_total: 144\n",
      "crawl_total: 143\n",
      "crawl_total: 142\n",
      "crawl_total: 141\n",
      "crawl_total: 140\n",
      "crawl_total: 139\n",
      "crawl_total: 138\n",
      "crawl_total: 137\n",
      "crawl_total: 136\n",
      "crawl_total: 135\n",
      "crawl_total: 134\n",
      "crawl_total: 133\n",
      "crawl_total: 132\n",
      "crawl_total: 131\n",
      "crawl_total: 130\n",
      "crawl_total: 129\n",
      "crawl_total: 128\n",
      "crawl_total: 127\n",
      "crawl_total: 126\n",
      "crawl_total: 125\n",
      "crawl_total: 124\n",
      "crawl_total: 123\n",
      "crawl_total: 122\n",
      "crawl_total: 121\n",
      "crawl_total: 120\n",
      "crawl_total: 119\n",
      "crawl_total: 118\n",
      "crawl_total: 117\n",
      "crawl_total: 116\n",
      "crawl_total: 115\n",
      "crawl_total: 114\n",
      "crawl_total: 113\n",
      "crawl_total: 112\n",
      "crawl_total: 111\n",
      "crawl_total: 110\n",
      "crawl_total: 109\n",
      "crawl_total: 108\n",
      "crawl_total: 107\n",
      "crawl_total: 106\n",
      "crawl_total: 105\n",
      "crawl_total: 104\n",
      "crawl_total: 103\n",
      "crawl_total: 102\n",
      "crawl_total: 101\n",
      "crawl_total: 100\n",
      "crawl_total: 99\n",
      "crawl_total: 98\n",
      "crawl_total: 97\n",
      "crawl_total: 96\n",
      "crawl_total: 95\n",
      "crawl_total: 94\n",
      "crawl_total: 93\n",
      "crawl_total: 92\n",
      "crawl_total: 91\n",
      "crawl_total: 90\n",
      "crawl_total: 89\n",
      "crawl_total: 88\n",
      "crawl_total: 87\n",
      "crawl_total: 86\n",
      "crawl_total: 85\n",
      "crawl_total: 84\n",
      "crawl_total: 83\n",
      "crawl_total: 82\n",
      "crawl_total: 81\n",
      "crawl_total: 80\n",
      "crawl_total: 79\n",
      "crawl_total: 78\n",
      "crawl_total: 77\n",
      "crawl_total: 76\n",
      "crawl_total: 75\n",
      "crawl_total: 74\n",
      "crawl_total: 73\n",
      "crawl_total: 72\n",
      "crawl_total: 71\n",
      "crawl_total: 70\n",
      "crawl_total: 69\n",
      "crawl_total: 68\n",
      "crawl_total: 67\n",
      "crawl_total: 66\n",
      "crawl_total: 65\n",
      "crawl_total: 64\n",
      "crawl_total: 63\n",
      "crawl_total: 62\n",
      "crawl_total: 61\n",
      "crawl_total: 60\n",
      "crawl_total: 59\n",
      "crawl_total: 58\n",
      "crawl_total: 57\n",
      "crawl_total: 56\n",
      "crawl_total: 55\n",
      "crawl_total: 54\n",
      "crawl_total: 53\n",
      "crawl_total: 52\n",
      "crawl_total: 51\n",
      "crawl_total: 50\n",
      "crawl_total: 49\n",
      "crawl_total: 48\n",
      "crawl_total: 47\n",
      "crawl_total: 46\n",
      "crawl_total: 45\n",
      "crawl_total: 44\n",
      "crawl_total: 43\n",
      "crawl_total: 42\n",
      "crawl_total: 41\n",
      "crawl_total: 40\n",
      "crawl_total: 39\n",
      "crawl_total: 38\n",
      "crawl_total: 37\n",
      "crawl_total: 36\n",
      "crawl_total: 35\n",
      "crawl_total: 34\n",
      "crawl_total: 33\n",
      "crawl_total: 32\n",
      "crawl_total: 31\n",
      "crawl_total: 30\n",
      "crawl_total: 29\n",
      "crawl_total: 28\n",
      "crawl_total: 27\n",
      "crawl_total: 26\n",
      "crawl_total: 25\n",
      "crawl_total: 24\n",
      "crawl_total: 23\n",
      "crawl_total: 22\n",
      "crawl_total: 21\n",
      "crawl_total: 20\n",
      "crawl_total: 19\n",
      "crawl_total: 18\n",
      "crawl_total: 17\n",
      "crawl_total: 16\n",
      "crawl_total: 15\n",
      "crawl_total: 14\n",
      "crawl_total: 13\n",
      "crawl_total: 12\n",
      "crawl_total: 11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "crawl_total: 10\n",
      "crawl_total: 9\n",
      "crawl_total: 8\n",
      "crawl_total: 7\n",
      "crawl_total: 6\n",
      "crawl_total: 5\n",
      "crawl_total: 4\n",
      "crawl_total: 3\n",
      "crawl_total: 2\n",
      "crawl_total: 1\n",
      "crawl_total: 0\n"
     ]
    }
   ],
   "source": [
    "while crawl_total > 0:\n",
    "    i = crawl_turns\n",
    "    j = (i + 1) % 2\n",
    "    arr[j] = []\n",
    "    crawl_turns = (crawl_turns + 1) % 2\n",
    "    #遍历列表，爬取所有网页\n",
    "    for element in arr[i]:\n",
    "        #获取网页内容\n",
    "        html_doc,success_crwal = getHtml(element)\n",
    "        if success_crwal:\n",
    "            #需爬取网页总数-1\n",
    "            if crawl_total <= 0:\n",
    "                break\n",
    "            crawl_total -= 1\n",
    "            print('crawl_total:',crawl_total)\n",
    "            soup = BeautifulSoup(html_doc, 'html.parser')\n",
    "            #处理后写入文件\n",
    "            f = codecs.open('./saved_html/' + str(crawl_total) + '.txt',\"w\",encoding=\"utf-8\")\n",
    "            f.write(processHtml(element, str(soup)))\n",
    "            f.close()\n",
    "            if save_total <= 0:\n",
    "                #需要保存的网页总数足够，不用继续保存\n",
    "                continue\n",
    "            link_arr = [s.extract() for s in soup('a')]\n",
    "            for element_addr in link_arr:\n",
    "                try:\n",
    "                    addr = element_addr['href'][0]\n",
    "                    #链接指向网页\n",
    "                    if ((addr == 'h' or addr == '/') and (not element_addr['href'].split()[0].endswith('.apk'))):\n",
    "                        if addr == '/':\n",
    "                            #相对链接\n",
    "                            addr = element.split('//')[0] + '//' + element.split('//')[1].split('/')[0] + element_addr['href'].split()[0]\n",
    "                            #链接不在已访问列表中\n",
    "                            if addr not in arr[2]:\n",
    "                                #是符合要求的网页，需要保存的总网页数-1\n",
    "                                save_total -= 1\n",
    "                                arr[j].append(addr)\n",
    "                                arr[2].append(addr)\n",
    "                                pass\n",
    "                            pass\n",
    "                        else:\n",
    "                            #绝对链接\n",
    "                            addr = element_addr['href'].split()[0]\n",
    "                            #链接不在已访问列表中\n",
    "                            if addr not in arr[2]:\n",
    "                                #是符合要求的网页，需要保存的总网页数-1\n",
    "                                save_total -= 1\n",
    "                                arr[j].append(addr)\n",
    "                                arr[2].append(addr)\n",
    "                                pass\n",
    "                            pass\n",
    "                except:\n",
    "                    pass\n",
    "                pass\n",
    "            pass\n",
    "        else:\n",
    "            save_total += 1\n",
    "            pass\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
